"use strict";(self.webpackChunkwebsite_docusaurus=self.webpackChunkwebsite_docusaurus||[]).push([[5413],{8034:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"api-guide/gpu/gpu-bindings","title":"Understanding Bindings","description":"luma.gl offers support for setting up (\\"binding\\") data required by the GPU during shader execution, including:","source":"@site/../docs/api-guide/gpu/gpu-bindings.md","sourceDirName":"api-guide/gpu","slug":"/api-guide/gpu/gpu-bindings","permalink":"/docs/api-guide/gpu/gpu-bindings","draft":false,"unlisted":false,"editUrl":"https://github.com/visgl/luma.gl/tree/master/docs/../docs/api-guide/gpu/gpu-bindings.md","tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"Using GPU Parameters","permalink":"/docs/api-guide/gpu/gpu-parameters"},"next":{"title":"Attributes","permalink":"/docs/api-guide/gpu/gpu-attributes"}}');var a=t(4848),s=t(8453);const o={},r="Understanding Bindings",d={},l=[{value:"Background",id:"background",level:2},{value:"Shader Layout",id:"shader-layout",level:2},{value:"Attribute Layout",id:"attribute-layout",level:3},{value:"Buffer Mapping",id:"buffer-mapping",level:3},{value:"Model usage",id:"model-usage",level:2},{value:"Types",id:"types",level:2},{value:"<code>ShaderLayout</code>",id:"shaderlayout",level:3},{value:"<code>AttributeLayout</code>",id:"attributelayout",level:3},{value:"Advanced Example",id:"advanced-example",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"understanding-bindings",children:"Understanding Bindings"})}),"\n",(0,a.jsx)(n.p,{children:'luma.gl offers support for setting up ("binding") data required by the GPU during shader execution, including:'}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"attribute buffers"}),"\n",(0,a.jsx)(n.li,{children:"bindings (uniform buffers, textures, samplers, ...)"}),"\n",(0,a.jsx)(n.li,{children:"uniforms"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,a.jsx)(n.p,{children:'A key responsibility of any GPU framework is to make enable the application to\nset up (or "bind") data so that it can be accessed by shader code running on the GPU.'}),"\n",(0,a.jsx)(n.p,{children:'Shaders contain declarations of external inputs such as attributes, uniform blocks, samplers etc.\nCollectively, these inputs define data that the CPU (the application) needs to be provide to the GPU\n(typically by "binding" data to the right "locations").'}),"\n",(0,a.jsx)(n.h2,{id:"shader-layout",children:"Shader Layout"}),"\n",(0,a.jsx)(n.p,{children:"luma.gl needs a certain amount of metadata describing what bindings a specific shader (or pair of vertex and fragment shaders) expects."}),"\n",(0,a.jsxs)(n.p,{children:["luma.gl expects this metadata to be conform to the ",(0,a.jsx)(n.code,{children:"ShaderLayout"})," type, and a ",(0,a.jsx)(n.code,{children:"ShaderLayout"}),"-conforming object\nis required when creating a ",(0,a.jsx)(n.code,{children:"RenderPipeline"})," or ",(0,a.jsx)(n.code,{children:"ComputePipeline"}),".\nNote that while ",(0,a.jsx)(n.code,{children:"ShaderLayout"}),"s must be created manually for WebGPU devices,\nluma.gl can generate them automatically on WebGL devices (using WebGL program introspection APIs)."]}),"\n",(0,a.jsx)(n.p,{children:"Shaders expose numeric bindings, however in applications, named bindings tend to be more convenient,\nand the ShaderLayout does include information on both names, locations and formats."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"type ShaderLayout = {\n  attributes: {\n    {name: 'instancePositions', location: 0, format: 'float32x2', stepMode: 'instance'},\n    {name: 'instanceVelocities', location: 1, format: 'float32x2', stepMode: 'instance'},\n    {name: 'vertexPositions', location: 2, format: 'float32x2', stepMode: 'vertex'}\n  },\n\n  bindings: {\n    {name: 'projectionUniforms', location: 0, type: 'uniforms'},\n    {name: 'textureSampler', location: 1, type: 'sampler'},\n    {name: 'texture', location: 2, type: 'texture'}\n  }\n}\n\ndevice.createRenderPipeline({\n  layout,\n  attributes,\n  bindings\n});\n"})}),"\n",(0,a.jsx)(n.h3,{id:"attribute-layout",children:"Attribute Layout"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"const shaderLayout: ShaderLayout = {\n  attributes: [\n    {name: 'instancePositions', location: 0, format: 'float32x2', stepMode: 'instance'},\n    {name: 'instanceVelocities', location: 1, format: 'float32x2', stepMode: 'instance'},\n    {name: 'vertexPositions', location: 2, format: 'float32x2', stepMode: 'vertex'}\n  ],\n  ...\n};\n"})}),"\n",(0,a.jsx)(n.h3,{id:"buffer-mapping",children:"Buffer Mapping"}),"\n",(0,a.jsx)(n.p,{children:'For many use cases, supplying a single, "canonically" formatted buffer per attribute is sufficient.\nHowever, sometimes an application may want to use more sophisticated GPU buffer layouts,\ncontrolling GPU buffer offsets, strides, interleaving etc.'}),"\n",(0,a.jsx)(n.p,{children:"Buffer mapping is an optional feature enabling custom buffer layouts and buffer interleaving."}),"\n",(0,a.jsx)(n.p,{children:"Note that buffer mappings need to be defined when a pipeline is created,\nand all buffers subsequently supplied to that pipeline need to conform to the buffer mapping."}),"\n",(0,a.jsxs)(n.p,{children:["Example: The ",(0,a.jsx)(n.code,{children:"bufferLayout"})," field in the example below specifies that both the\n",(0,a.jsx)(n.code,{children:"instancePositions"})," and ",(0,a.jsx)(n.code,{children:"instanceVelocities"}),' attributes should be read from a single,\ninterleaved buffer. In this example, since no strides are provided, supplied buffers are assumed to be "packed",\nwith alternating "position" and "velocity" values with no padding in between.']}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"device.createRenderPipeline({\n  shaderLayout: {\n    attributes: [\n      {name: 'instancePositions', location: 0, format: 'float32x2', stepMode: 'instance'},\n      {name: 'instanceVelocities', location: 1, format: 'float32x2', stepMode: 'instance'},\n      {name: 'vertexPositions', location: 2, format: 'float32x2', stepMode: 'vertex'}\n    ],\n    ...\n  },\n  // We want to use \"non-standard\" buffers: two attributes interleaved in same buffer\n  bufferLayout: [\n    {name: 'particles', attributes: [\n      {name: 'instancePositions'},\n      {name: 'instanceVelocities'}\n    ]\n  ],\n  attributes: {\n    particles: device.createBuffer(...)\n  },\n  bindings: {}\n});\n"})}),"\n",(0,a.jsx)(n.h2,{id:"model-usage",children:"Model usage"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"new Model(device, {\n  shaderLayout: {\n    attributes: {\n      instancePositions: {location: 0, format: 'float32x2', stepMode: 'instance'},\n      instanceVelocities: {location: 1, format: 'float32x2', stepMode: 'instance'},\n      vertexPositions: {location: 2, format: 'float32x2', stepMode: 'vertex'}\n    }\n  }\n});\n"})}),"\n",(0,a.jsx)(n.h2,{id:"types",children:"Types"}),"\n",(0,a.jsx)(n.h3,{id:"shaderlayout",children:(0,a.jsx)(n.code,{children:"ShaderLayout"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"export type ShaderLayout = {\n  attributes: AttributeLayout[];\n  bindings: BindingLayout[];\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"attributelayout",children:(0,a.jsx)(n.code,{children:"AttributeLayout"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["name = ",(0,a.jsx)(n.code,{children:"string"})]}),"\n",(0,a.jsxs)(n.li,{children:["location - ",(0,a.jsx)(n.code,{children:"number"})]}),"\n",(0,a.jsxs)(n.li,{children:["format - ",(0,a.jsx)(n.code,{children:"VertexFormat"})]}),"\n",(0,a.jsxs)(n.li,{children:["stepMode - ",(0,a.jsx)(n.code,{children:"'vertex' \\| 'instance'"})]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"advanced-example",children:"Advanced Example"}),"\n",(0,a.jsx)(n.p,{children:"WGSL vertex shader"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-rust",children:"struct Uniforms {\n  modelViewProjectionMatrix : mat4x4<f32>;\n};\n@binding(0), @group(0) var<uniform> uniforms : Uniforms; // BINDING 0\n\nstruct VertexOutput {\n  @builtin(position) Position : vec4<f32>;\n  @location(0) fragUV : vec2<f32>;\n  @location(1) fragPosition: vec4<f32>;\n};\n\n@stage(vertex)\nfn main(@location(0) position : vec4<f32>,\n        @location(1) uv : vec2<f32>) -> VertexOutput {\n  var output : VertexOutput;\n  output.Position = uniforms.modelViewProjectionMatrix * position;\n  output.fragUV = uv;\n  output.fragPosition = 0.5 * (position + vec4<f32>(1.0, 1.0, 1.0, 1.0));\n  return output;\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"WGSL Fragment Shader"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-rust",children:"@group(0), binding(1) var mySampler: sampler; // BINDING 1\n@group(0), binding(2) var myTexture: texture_2d<f32>; // BINDING 2\n\n@stage(fragment)\nfn main(@location(0) fragUV: vec2<f32>,\n        @location(1) fragPosition: vec4<f32>) -> [[location(0)]] vec4<f32> {\n  return textureSample(myTexture, mySampler, fragUV) * fragPosition;\n}\n"})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(6540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);