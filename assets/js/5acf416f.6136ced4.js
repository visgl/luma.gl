/*! For license information please see 5acf416f.6136ced4.js.LICENSE.txt */
"use strict";(self.webpackChunkwebsite_docusaurus=self.webpackChunkwebsite_docusaurus||[]).push([[4531],{3848:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>d,metadata:()=>l,toc:()=>a});var s=t(4848),n=t(8453);const d={},i="Texture",l={id:"api-reference/core/resources/texture",title:"Texture",description:"A Texture is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a sampler uniform) and they can be set up as render targets (by attaching them to a framebuffer).",source:"@site/../docs/api-reference/core/resources/texture.md",sourceDirName:"api-reference/core/resources",slug:"/api-reference/core/resources/texture",permalink:"/docs/api-reference/core/resources/texture",draft:!1,unlisted:!1,editUrl:"https://github.com/visgl/luma.gl/tree/main/docs/../docs/api-reference/core/resources/texture.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Shader Logs",permalink:"/docs/api-reference/core/shader-logs"},next:{title:"TextureView",permalink:"/docs/api-reference/core/resources/texture-view"}},c={},a=[{value:"Usage",id:"usage",level:2},{value:"Types",id:"types",level:2},{value:"<code>BufferProps</code>",id:"bufferprops",level:3},{value:"Usage",id:"usage-1",level:3},{value:"TextureDimension",id:"texturedimension",level:2},{value:"TextureData",id:"texturedata",level:2},{value:"Members",id:"members",level:2},{value:"Members",id:"members-1",level:2},{value:"Methods",id:"methods",level:2},{value:"<code>constructor(props: TextureProps)</code>",id:"constructorprops-textureprops",level:3},{value:"<code>destroy(): void</code>",id:"destroy-void",level:3},{value:"resize(options : Object) : Texture2D",id:"resizeoptions--object--texture2d",level:3},{value:"generateMipmap() : Texture2D",id:"generatemipmap--texture2d",level:3},{value:"setImageData(options : Object) : Texture2D",id:"setimagedataoptions--object--texture2d",level:3},{value:"setSubImageData(options : Object) : Texture2D",id:"setsubimagedataoptions--object--texture2d",level:3},{value:"update()",id:"update",level:3},{value:"Remarks",id:"remarks",level:2}];function o(e){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.h1,{id:"texture",children:"Texture"}),"\n",(0,s.jsxs)(r.p,{children:["A ",(0,s.jsx)(r.code,{children:"Texture"})," is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a sampler uniform) and they can be set up as render targets (by attaching them to a framebuffer)."]}),"\n",(0,s.jsxs)(r.p,{children:["Note: This section describes the ",(0,s.jsx)(r.code,{children:"Texture"})," base class that implements functionality common to all four types of WebGL:"]}),"\n",(0,s.jsxs)(r.p,{children:["For more details see ",(0,s.jsx)(r.a,{href:"https://www.khronos.org/opengl/wiki/Texture",children:"OpenGL Wiki"}),"."]}),"\n",(0,s.jsx)(r.p,{children:"Note that textures have a lot of optional capabilities made available by extensions, see the Limits section below."}),"\n",(0,s.jsx)(r.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(r.p,{children:"Creating a texture"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-typescript",children:"const texture = device.createTexture({sampler: {addressModeU: 'clamp-to-edge'});\n"})}),"\n",(0,s.jsx)(r.p,{children:"Using Textures"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-typescript",children:"const texture = device.createTexture, ...);\n\n// For ease of use, the `Model` class can bind textures for a draw call\nmodel.draw({\n  uniforms({uMVMatrix: matrix, texture1: texture, texture2: texture})\n});\n\n// Alternatively, bind the textures using the `Texture` API directly\ntexture.bind(0);\ntexture.bind(1);\nmodel.draw({\n  uniforms({uMVMatrix: matrix})\n});\n"})}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:["For additional usage examples, ",(0,s.jsx)(r.code,{children:"Texture"})," inherits from ",(0,s.jsx)(r.code,{children:"Resource"}),"."]}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"types",children:"Types"}),"\n",(0,s.jsx)(r.h3,{id:"bufferprops",children:(0,s.jsx)(r.code,{children:"BufferProps"})}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Property"}),(0,s.jsx)(r.th,{children:"Type"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"usage?"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"number"})}),(0,s.jsx)(r.td,{children:"Bit mask of Usage flags"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"byteLength?"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"number"})}),(0,s.jsx)(r.td,{children:"Length of buffer (cannot be changed after creation)."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"data?"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"ArrayBuffer | ArrayBufferView"})}),(0,s.jsxs)(r.td,{children:["Data to be copied into buffer. ",(0,s.jsx)(r.code,{children:"byteLength"})," will be deduced if not supplied."]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"byteOffset?"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"number"})}),(0,s.jsxs)(r.td,{children:["Offset for ",(0,s.jsx)(r.code,{children:"data"})]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"indexType?"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"'uint16' | 'uint32'"})}),(0,s.jsx)(r.td,{children:"If props.usage & Buffer.INDEX"})]})]})]}),"\n",(0,s.jsx)(r.h3,{id:"usage-1",children:"Usage"}),"\n",(0,s.jsx)(r.p,{children:"Usage expresses two things: The type of texture and what operations can be performed on it."}),"\n",(0,s.jsx)(r.p,{children:"Note that the allowed combinations are very limited, especially in WebGPU."}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Usage Flag"}),(0,s.jsx)(r.th,{children:"Value"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Texture.COPY_SRC"})}),(0,s.jsx)(r.td,{children:"0x01"}),(0,s.jsx)(r.td,{})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Texture.COPY_DST"})}),(0,s.jsx)(r.td,{children:"0x02"}),(0,s.jsx)(r.td,{})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Texture.TEXTURE"})}),(0,s.jsx)(r.td,{children:"0x04"}),(0,s.jsx)(r.td,{})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Texture.STORAGE_BINDING"})}),(0,s.jsx)(r.td,{children:"0x08"}),(0,s.jsx)(r.td,{})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Texture.RENDER_ATTACHMENT"})}),(0,s.jsx)(r.td,{children:"0x10"}),(0,s.jsx)(r.td,{})]})]})]}),"\n",(0,s.jsx)(r.h2,{id:"texturedimension",children:"TextureDimension"}),"\n",(0,s.jsxs)(r.p,{children:["| Dimension    | WebGPU | WebGL2 | Description                                                          |\n| ------------ | ------ | ------ | | -------------------------------------------------------------------- |\n| ",(0,s.jsx)(r.code,{children:"1d"}),"         | \u2705      | \u274c      | Contains a one dimensional texture (typically used for compute )     |\n| ",(0,s.jsx)(r.code,{children:"2d"}),'         | \u2705      | \u2705      | Contains a "normal" image texture                                    |\n| ',(0,s.jsx)(r.code,{children:"2d-array"}),'   | \u2705      | \u2705      | Holds an "array" of 2D textures.                                     |\n| ',(0,s.jsx)(r.code,{children:"3d"}),'         | \u2705      | \u2705      | Holds a "stack" of textures which enables 3D interpolation.          |\n| ',(0,s.jsx)(r.code,{children:"cube"}),"       | \u2705      | \u2705      | Holds 6 textures representing sides of a cube.                       |\n| ",(0,s.jsx)(r.code,{children:"cube-array"})," | \u2705      | \u274c      | Holds an array where every 6 textures represent the sides of a cube. |"]}),"\n",(0,s.jsx)(r.h2,{id:"texturedata",children:"TextureData"}),"\n",(0,s.jsx)(r.p,{children:"WebGL allows textures to be created from a number of different data sources."}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Type"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"null"})}),(0,s.jsx)(r.td,{children:'A texture will be created with the appropriate format, size and width. Bytes will be "uninitialized".'})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"typed array"})}),(0,s.jsx)(r.td,{children:"Bytes will be interpreted according to format/type parameters and pixel store parameters."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"Buffer"})}),(0,s.jsx)(r.td,{children:"Bytes will be interpreted according to format/type parameters and pixel store parameters."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"Image"})," (",(0,s.jsx)(r.code,{children:"HTMLImageElement"}),")"]}),(0,s.jsx)(r.td,{children:"image will be used to fill the texture. width and height will be deduced."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"Video"})," (",(0,s.jsx)(r.code,{children:"HTMLVideoElement"}),")"]}),(0,s.jsx)(r.td,{children:"video will be used to continously update the texture. width and height will be deduced."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"Canvas"})," (",(0,s.jsx)(r.code,{children:"HTMLCanvasElement"}),")"]}),(0,s.jsx)(r.td,{children:"canvas will be used to fill the texture. width and height will be deduced."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"ImageData"})}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"canvas.getImageData()"})," - Used to fill the texture. width and height will be deduced."]})]})]})]}),"\n",(0,s.jsx)(r.h2,{id:"members",children:"Members"}),"\n",(0,s.jsx)(r.p,{children:"A number of read only accessors are available:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"width"})," - width of one face of the cube map"]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"height"})," - height of one face of the cube map"]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"format"})," - internal format of the face textures"]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"border"})," - Always 0."]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"type"})," - type used to create face textures"]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"dataFormat"})," - data format used to create face textures."]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"offset"})," - offset used to create face textures."]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"handle"})," - The underlying WebGL or WebGPU object."]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"id"})," - An identifying string that is intended to help debugging."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:["Sampler parameters can be accessed using ",(0,s.jsx)(r.code,{children:"Texture.getParameter"}),", e.g:"]}),"\n",(0,s.jsx)(r.p,{children:(0,s.jsx)(r.code,{children:"texture.getParameter(GL.TEXTURE_MAG_FILTER);"})}),"\n",(0,s.jsx)(r.h2,{id:"members-1",children:"Members"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"device"}),": ",(0,s.jsx)(r.code,{children:"Device"})," - holds a reference to the ",(0,s.jsx)(r.code,{children:"Device"})," that created this ",(0,s.jsx)(r.code,{children:"Texture"}),"."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"handle"}),": ",(0,s.jsx)(r.code,{children:"unknown"})," - holds the underlying WebGL or WebGPU shader object"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"props"}),": ",(0,s.jsx)(r.code,{children:"TextureProps"})," - holds a copy of the ",(0,s.jsx)(r.code,{children:"TextureProps"})," used to create this ",(0,s.jsx)(r.code,{children:"Texture"}),"."]}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"methods",children:"Methods"}),"\n",(0,s.jsx)(r.h3,{id:"constructorprops-textureprops",children:(0,s.jsx)(r.code,{children:"constructor(props: TextureProps)"})}),"\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.code,{children:"Texture"})," is an abstract class and cannot be instantiated directly. Create with ",(0,s.jsx)(r.code,{children:"device.createTexture(...)"}),"."]}),"\n",(0,s.jsx)(r.h3,{id:"destroy-void",children:(0,s.jsx)(r.code,{children:"destroy(): void"})}),"\n",(0,s.jsx)(r.p,{children:"Free up any GPU resources associated with this texture immediately (instead of waiting for garbage collection)."}),"\n",(0,s.jsx)(r.h3,{id:"resizeoptions--object--texture2d",children:"resize(options : Object) : Texture2D"}),"\n",(0,s.jsxs)(r.p,{children:["Call to resize a texture. If size has changed, reinitializes texture with current format. Note: calling ",(0,s.jsx)(r.code,{children:"resize"})," clears image and mipmaps."]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"width"})," (GLint) - width to resize to."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"height"})," (GLint) - height to resize to."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"mipmaps"})," (bool) - turn on/off mipmapping. default ",(0,s.jsx)(r.code,{children:"false"}),"."]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"generatemipmap--texture2d",children:"generateMipmap() : Texture2D"}),"\n",(0,s.jsx)(r.p,{children:"Call to regenerate mipmaps after modifying texture(s)"}),"\n",(0,s.jsxs)(r.p,{children:["WebGL References ",(0,s.jsx)(r.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/generateMipmap",children:"gl.generateMipmap"})]}),"\n",(0,s.jsx)(r.h3,{id:"setimagedataoptions--object--texture2d",children:"setImageData(options : Object) : Texture2D"}),"\n",(0,s.jsx)(r.p,{children:"Allocates storage and sets image data"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-typescript",children:"  Texture.setImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    width,\n    height,\n    level = 0,\n    type,\n    offset = 0,\n    border = 0,\n    compressed = false,\n    parameters= {}\n  });\n"})}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"data"})," (*) - Image data. Can be one of several data types see table below"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"pixels"})," (*) - alternative to ",(0,s.jsx)(r.code,{children:"data"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"width"})," (GLint) -"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"height"})," (GLint) -"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"level"})," (GLint) -"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"format"})," (GLenum) - format of image data."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"type"})," (GLenum)"]}),"\n"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"format of array (autodetect from type) or"}),"\n",(0,s.jsx)(r.li,{children:"(WEBGL2) format of buffer"}),"\n"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"offset"})," (Number) - (WEBGL2) offset from start of buffer"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"border"})," (GLint) - must be 0."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"compressed"})," (Boolean) -"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"parameters"})," (Object) - GL parameters to be temporarily applied (most of the time, pixelStorage parameters) when updating the texture."]}),"\n"]}),"\n",(0,s.jsx)(r.p,{children:"Valid image data types:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"null"})," - create empty texture of specified format"]}),"\n",(0,s.jsxs)(r.li,{children:["Typed array - initializes from image data in typed array according to ",(0,s.jsx)(r.code,{children:"format"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"Buffer"}),"|",(0,s.jsx)(r.code,{children:"WebGLBuffer"})," - (WEBGL2) initialized from image data in WebGLBuffer accoeding to ",(0,s.jsx)(r.code,{children:"format"}),"."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"HTMLImageElement"}),"|",(0,s.jsx)(r.code,{children:"Image"})," - Initializes with content of image. Auto deduces texture width/height from image."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"HTMLCanvasElement"})," - Inits with contents of canvas. Auto width/height."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"HTMLVideoElement"})," - Creates video texture that continuously updates. Auto width/height."]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"setsubimagedataoptions--object--texture2d",children:"setSubImageData(options : Object) : Texture2D"}),"\n",(0,s.jsx)(r.p,{children:"Redefines an area of an existing texture\nNote: does not allocate storage"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"  Texture.setSubImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    x = 0,\n    y = 0,\n    width,\n    height,\n    level = 0,\n    type,\n    compressed = false,\n    offset = 0,\n    border = 0,\n    parameters = {}\n  });\n"})}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"x"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - xOffset from where texture to be updated"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"y"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - yOffset from where texture to be updated"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"width"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - width of the sub image to be updated"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"height"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - height of the sub image to be updated"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"level"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - mip level to be updated"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"format"})," (",(0,s.jsx)(r.code,{children:"GLenum"}),") - internal format of image data."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"typ"})," (",(0,s.jsx)(r.code,{children:"GLenum"}),") - format of array (autodetect from type) or (WEBGL2) format of buffer or ArrayBufferView"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"dataFormat"})," (",(0,s.jsx)(r.code,{children:"GLenum"}),") - format of image data."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"offset"})," (",(0,s.jsx)(r.code,{children:"Number"}),") - (WEBGL2) offset from start of buffer"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"border"})," (",(0,s.jsx)(r.code,{children:"GLint"}),") - must be 0."]}),"\n",(0,s.jsx)(r.li,{children:"parameters - temporary settings to be applied, can be used to supply pixel store settings."}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:["See also ",(0,s.jsx)(r.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/compressedTexSubImage2D",children:"gl.compressedTexSubImage2D"}),", ",(0,s.jsx)(r.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texSubImage2D",children:"gl.texSubImage2D"}),", ",(0,s.jsx)(r.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture",children:"gl.bindTexture"}),", ",(0,s.jsx)(r.a,{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindBuffer",children:"gl.bindBuffer"})]}),"\n",(0,s.jsx)(r.h3,{id:"update",children:"update()"}),"\n",(0,s.jsxs)(r.p,{children:["Update this texture if ",(0,s.jsx)(r.code,{children:"HTMLVideoElement"})," is used as the data source. This method is automatically called before every draw call if this texture is bound to a uniform."]}),"\n",(0,s.jsx)(r.h2,{id:"remarks",children:"Remarks"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"Textures can be supplied as uniforms to shaders that can sample them using texture coordinates and color pixels accordingly."}),"\n",(0,s.jsx)(r.li,{children:"Parameters that affect texture sampling can be set on textures or sampler objects."}),"\n",(0,s.jsx)(r.li,{children:"Textures can be created from a number of different sources, including typed arrays, HTML Images, HTML Canvases, HTML Videos and WebGLBuffers (WebGL 2)."}),"\n",(0,s.jsx)(r.li,{children:'The WebGL Context has global "pixel store" parameters that control how pixel data is laid out, including Y direction, color space etc.'}),"\n",(0,s.jsx)(r.li,{children:"Textures are read from supplied data and written to the specified format/type parameters and pixel store parameters."}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,n.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},1020:(e,r,t)=>{var s=t(6540),n=Symbol.for("react.element"),d=Symbol.for("react.fragment"),i=Object.prototype.hasOwnProperty,l=s.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,c={key:!0,ref:!0,__self:!0,__source:!0};function a(e,r,t){var s,d={},a=null,o=null;for(s in void 0!==t&&(a=""+t),void 0!==r.key&&(a=""+r.key),void 0!==r.ref&&(o=r.ref),r)i.call(r,s)&&!c.hasOwnProperty(s)&&(d[s]=r[s]);if(e&&e.defaultProps)for(s in r=e.defaultProps)void 0===d[s]&&(d[s]=r[s]);return{$$typeof:n,type:e,key:a,ref:o,props:d,_owner:l.current}}r.Fragment=d,r.jsx=a,r.jsxs=a},4848:(e,r,t)=>{e.exports=t(1020)},8453:(e,r,t)=>{t.d(r,{R:()=>i,x:()=>l});var s=t(6540);const n={},d=s.createContext(n);function i(e){const r=s.useContext(d);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:i(e.components),s.createElement(d.Provider,{value:r},e.children)}}}]);