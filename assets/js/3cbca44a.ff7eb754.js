"use strict";(self.webpackChunkwebsite_docusaurus=self.webpackChunkwebsite_docusaurus||[]).push([[226],{8393:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>l,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"api-guide/gpu/gpu-memory","title":"GPU Memory","description":"Memory on GPU is managed through Buffer and Texture resources.","source":"@site/../docs/api-guide/gpu/gpu-memory.md","sourceDirName":"api-guide/gpu","slug":"/api-guide/gpu/gpu-memory","permalink":"/docs/api-guide/gpu/gpu-memory","draft":false,"unlisted":false,"editUrl":"https://github.com/visgl/luma.gl/tree/master/docs/../docs/api-guide/gpu/gpu-memory.md","tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"GPU Resources","permalink":"/docs/api-guide/gpu/gpu-resources"},"next":{"title":"Using GPU Buffers","permalink":"/docs/api-guide/gpu/gpu-buffers"}}');var i=o(4848),t=o(8453);const s={},a="GPU Memory",d={},c=[{value:"Memory Upload Considerations",id:"memory-upload-considerations",level:2},{value:"Memory Operation Synchronization",id:"memory-operation-synchronization",level:2},{value:"Synchronous Reads",id:"synchronous-reads",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"gpu-memory",children:"GPU Memory"})}),"\n",(0,i.jsxs)(n.p,{children:["Memory on GPU is managed through ",(0,i.jsx)(n.a,{href:"/docs/api-guide/gpu/gpu-buffers",children:"Buffer"})," and ",(0,i.jsx)(n.a,{href:"/docs/api-guide/gpu/gpu-textures",children:"Texture"})," resources."]}),"\n",(0,i.jsx)(n.p,{children:"This article provides some background information on how GPU memory works that can be helpful in understanding limitations and performance characteristics."}),"\n",(0,i.jsx)(n.h2,{id:"memory-upload-considerations",children:"Memory Upload Considerations"}),"\n",(0,i.jsx)(n.p,{children:"Many GPUs are separated from the main CPU and cannot directly access main memory."}),"\n",(0,i.jsx)(n.p,{children:'There are configurations, such as built-in GPUs like Intel Iris, that share memory with the CPU using a "Unified Memory Architecture".'}),"\n",(0,i.jsx)(n.p,{children:"While the upload and download of data between GPU and CPU is still very fast, it does add complications:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"requires copying of potentially big memory blocks which takes some time"}),"\n",(0,i.jsx)(n.li,{children:"can increase memory pressure by permanently or temporarily requiring the application to allocate two copies of each memory block, one on the GPU and one on the CPU."}),"\n",(0,i.jsx)(n.li,{children:"makes the amount of memory limited to whichever is smaller, GPU memory or CPU memory."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In addition, this means that upload and download API is asynchronous which can add additional complexity to applications."}),"\n",(0,i.jsx)(n.h2,{id:"memory-operation-synchronization",children:"Memory Operation Synchronization"}),"\n",(0,i.jsx)(n.p,{children:"A GPU memory read or write may not always be completed immediately."}),"\n",(0,i.jsx)(n.p,{children:"GPUs executes its own commands queues independently from the CPU (the GPU and GPU driver may even optimize execution by rearranging order of operations). Therefore, to avoid unpredictable results, GPUs typically track the memory dependencies of each GPU operation, making sure that all preceding commands affecting a Buffer or Texture have completed in order before issuing e.g. a write or read."}),"\n",(0,i.jsx)(n.p,{children:"This is sometimes referred to as a read forcing a synchronization of the GPU."}),"\n",(0,i.jsx)(n.h2,{id:"synchronous-reads",children:"Synchronous Reads"}),"\n",(0,i.jsxs)(n.p,{children:["WebGL is plagued by a synchronous ",(0,i.jsx)(n.code,{children:"Buffer"})," readout limitation. Not only does the CPU block while waiting for the computers DMA system to read out the memory from the GPU, it also forces a synchronization, meaning that now the GPU must complete any pending commands before the GPU gets control back and can continue execution."]}),"\n",(0,i.jsx)(n.p,{children:"Note that a WebGL extension does exist that enables asynchronous buffer reads, but it is not implemented on MacOS which is the primary development environment for luma.gl, so at the moment of writing it is not supported by luma.gl."})]})}function l(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var r=o(6540);const i={},t=r.createContext(i);function s(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);